{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\sonym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (8.3.40)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\sonym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\sonym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (3.9.1)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\sonym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\sonym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (10.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\sonym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\sonym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\sonym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (1.14.0)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\sonym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (2.5.1+cu118)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\sonym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (0.20.1+cu118)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\sonym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (4.66.5)\n",
      "Requirement already satisfied: psutil in c:\\users\\sonym\\appdata\\roaming\\python\\python312\\site-packages (from ultralytics) (6.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\sonym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\sonym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\sonym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\sonym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (2.0.12)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sonym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sonym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sonym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\sonym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sonym\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\sonym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\sonym\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sonym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sonym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sonym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sonym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sonym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sonym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.7.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\sonym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\sonym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\sonym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sonym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\sonym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sonym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (70.3.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\sonym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sonym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sonym\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sonym\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sonym\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install ultralytics\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing training set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting annotations: 0it [00:00, ?it/s]\n",
      "Copying images: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing validation set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting annotations: 0it [00:00, ?it/s]\n",
      "Copying images: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from multiprocessing import cpu_count\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "BASE_DIR = '/content/drive/MyDrive/2학년/2학기/deeplearning/dataset'\n",
    "\n",
    "def create_dataset_structure():\n",
    "   \"\"\"데이터셋 디렉터리 구조 생성\"\"\"\n",
    "   dataset_path = os.path.join(BASE_DIR, 'dataset')\n",
    "   for split in ['train', 'val']:\n",
    "       for subdir in ['images', 'labels']:\n",
    "           os.makedirs(os.path.join(dataset_path, split, subdir), exist_ok=True)\n",
    "\n",
    "def process_single_file(args):\n",
    "   \"\"\"단일 annotation 파일을 YOLO 형식으로 변환\"\"\"\n",
    "   txt_file, annot_path, img_path, save_path, classes = args\n",
    "\n",
    "   img_file = txt_file.replace('.txt', '.jpg')\n",
    "   img = cv2.imread(os.path.join(img_path, img_file))\n",
    "   if img is None:\n",
    "       return\n",
    "\n",
    "   height, width = img.shape[:2]\n",
    "   yolo_annots = []\n",
    "\n",
    "   with open(os.path.join(annot_path, txt_file), 'r') as f:\n",
    "       for line in f:\n",
    "           try:\n",
    "               x, y, w, h, _, category, _, _ = map(float, line.strip().split(',')[:8])\n",
    "               category = str(int(category))\n",
    "\n",
    "               if category not in classes:\n",
    "                   continue\n",
    "\n",
    "               x_center = (x + w/2) / width\n",
    "               y_center = (y + h/2) / height\n",
    "               w = w / width\n",
    "               h = h / height\n",
    "\n",
    "               yolo_annots.append(f\"{classes[category]} {x_center} {y_center} {w} {h}\\n\")\n",
    "           except:\n",
    "               continue\n",
    "\n",
    "   if yolo_annots:\n",
    "       with open(os.path.join(save_path, txt_file), 'w') as f:\n",
    "           f.writelines(yolo_annots)\n",
    "\n",
    "def convert_visdrone_to_yolo(annot_path, img_path, save_path):\n",
    "   \"\"\"VisDrone 데이터를 YOLO 형식으로 변환\"\"\"\n",
    "   classes = {str(i): i-1 for i in range(1, 11)}\n",
    "   os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "   txt_files = list(Path(annot_path).glob(\"*.txt\"))\n",
    "   args_list = [(txt_file.name, annot_path, img_path, save_path, classes) for txt_file in txt_files]\n",
    "\n",
    "   with ProcessPoolExecutor(max_workers=cpu_count()) as executor:\n",
    "       list(tqdm(executor.map(process_single_file, args_list),\n",
    "                total=len(txt_files),\n",
    "                desc=\"Converting annotations\"))\n",
    "\n",
    "def copy_single_file(args):\n",
    "   \"\"\"단일 이미지 파일 복사\"\"\"\n",
    "   img_path, dst_img_path = args\n",
    "   shutil.copy2(img_path, dst_img_path)\n",
    "\n",
    "def copy_images_parallel(src_img_path, dst_img_path):\n",
    "   \"\"\"이미지 파일 병렬 복사\"\"\"\n",
    "   os.makedirs(dst_img_path, exist_ok=True)\n",
    "   images = list(Path(src_img_path).glob(\"*.jpg\"))\n",
    "\n",
    "   args_list = [(img_path, dst_img_path) for img_path in images]\n",
    "\n",
    "   with ProcessPoolExecutor(max_workers=cpu_count()) as executor:\n",
    "       list(tqdm(executor.map(copy_single_file, args_list),\n",
    "                total=len(images),\n",
    "                desc=\"Copying images\"))\n",
    "\n",
    "def process_dataset():\n",
    "   \"\"\"전체 데이터셋 처리\"\"\"\n",
    "   create_dataset_structure()\n",
    "\n",
    "   # Training set 처리\n",
    "   print(\"Processing training set...\")\n",
    "   train_annot = os.path.join(BASE_DIR, 'VisDrone2019-DET-train/annotations')\n",
    "   train_img = os.path.join(BASE_DIR, 'VisDrone2019-DET-train/images')\n",
    "   train_save = os.path.join(BASE_DIR, 'dataset/train/labels')\n",
    "\n",
    "   convert_visdrone_to_yolo(train_annot, train_img, train_save)\n",
    "   copy_images_parallel(train_img, os.path.join(BASE_DIR, 'dataset/train/images'))\n",
    "\n",
    "   # Validation set 처리\n",
    "   print(\"\\nProcessing validation set...\")\n",
    "   val_annot = os.path.join(BASE_DIR, 'VisDrone2019-DET-val/annotations')\n",
    "   val_img = os.path.join(BASE_DIR, 'VisDrone2019-DET-val/images')\n",
    "   val_save = os.path.join(BASE_DIR, 'dataset/val/labels')\n",
    "\n",
    "   convert_visdrone_to_yolo(val_annot, val_img, val_save)\n",
    "   copy_images_parallel(val_img, os.path.join(BASE_DIR, 'dataset/val/images'))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   process_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backup file not found\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import zipfile\n",
    "import os\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "BASE_DIR = 'C:\\Users\\sonym\\20242R0136COSE47402\\pretrained'\n",
    "\n",
    "def extract_file(zip_file, target_dir, file_name):\n",
    "    \"\"\"단일 파일 압축 해제 함수\"\"\"\n",
    "    # 디렉토리인 경우 생성만 하고 반환\n",
    "    if file_name.endswith('/'):\n",
    "        target_path = os.path.join(target_dir, file_name)\n",
    "        os.makedirs(target_path, exist_ok=True)\n",
    "        return\n",
    "\n",
    "    target_path = os.path.join(target_dir, file_name)\n",
    "    os.makedirs(os.path.dirname(target_path), exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        with zip_file.open(file_name) as source, open(target_path, 'wb') as target:\n",
    "            shutil.copyfileobj(source, target)\n",
    "    except:\n",
    "        print(f\"Error extracting: {file_name}\")\n",
    "\n",
    "def restore_dataset_from_backup():\n",
    "    \"\"\"병렬 압축 해제\"\"\"\n",
    "    backup_file = os.path.join(BASE_DIR, 'processed_dataset_backup.zip')\n",
    "    extract_dir = os.path.join(BASE_DIR, 'dataset')\n",
    "\n",
    "    if not os.path.exists(backup_file):\n",
    "        print(\"Backup file not found\")\n",
    "        return\n",
    "\n",
    "    print(\"Restoring dataset from backup...\")\n",
    "    os.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "    with zipfile.ZipFile(backup_file, 'r') as zip_file:\n",
    "        # 먼저 디렉토리 생성\n",
    "        file_list = zip_file.namelist()\n",
    "        directories = [f for f in file_list if f.endswith('/')]\n",
    "        for d in directories:\n",
    "            os.makedirs(os.path.join(extract_dir, d), exist_ok=True)\n",
    "\n",
    "        # 파일만 추출\n",
    "        files = [f for f in file_list if not f.endswith('/')]\n",
    "\n",
    "        # 병렬 압축 해제\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            list(tqdm(\n",
    "                executor.map(lambda f: extract_file(zip_file, extract_dir, f), files),\n",
    "                total=len(files),\n",
    "                desc=\"Extracting files\"\n",
    "            ))\n",
    "    print(\"Dataset restored successfully\")\n",
    "restore_dataset_from_backup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "BASE_DIR = 'C:/Users/sonym/20242R0136COSE47402/pretrained'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_yaml():\n",
    "    yaml_content = f\"\"\"\n",
    "path: {BASE_DIR}  # dataset root dir\n",
    "train: train/images\n",
    "val: val/images\n",
    "\n",
    "# Classes\n",
    "names:\n",
    "  0: pedestrian\n",
    "  1: people\n",
    "  2: bicycle\n",
    "  3: car\n",
    "  4: van\n",
    "  5: truck\n",
    "  6: tricycle\n",
    "  7: awning-tricycle\n",
    "  8: bus\n",
    "  9: motor\n",
    "\"\"\"\n",
    "    with open(os.path.join(BASE_DIR, 'visdrone.yaml'), 'w') as f:\n",
    "        f.write(yaml_content)\n",
    "\n",
    "create_yaml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.47 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.40  Python-3.12.4 torch-2.5.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4080, 16376MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=C:/Users/sonym/20242R0136COSE47402/pretrained\\visdrone.yaml, epochs=30, time=None, patience=5, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train6, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train6\n",
      "Overriding model.yaml nc=80 with nc=10\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    753262  ultralytics.nn.modules.head.Detect           [10, [64, 128, 256]]          \n",
      "Model summary: 225 layers, 3,012,798 parameters, 3,012,782 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train6', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\sonym\\20242R0136COSE47402\\pretrained\\train\\labels.cache... 6471 images, 0 backgrounds, 0 corrupt: 100%|██████████| 6471/6471 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\sonym\\20242R0136COSE47402\\pretrained\\train\\images\\0000137_02220_d_0000163.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\sonym\\20242R0136COSE47402\\pretrained\\train\\images\\0000140_00118_d_0000002.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\sonym\\20242R0136COSE47402\\pretrained\\train\\images\\9999945_00000_d_0000114.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\sonym\\20242R0136COSE47402\\pretrained\\train\\images\\9999987_00000_d_0000049.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\sonym\\20242R0136COSE47402\\pretrained\\val\\labels.cache... 548 images, 0 backgrounds, 0 corrupt: 100%|██████████| 548/548 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train6\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train6\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/30      8.54G      1.845      2.391       1.04        461        640: 100%|██████████| 405/405 [00:36<00:00, 11.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:02<00:00,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.291      0.172      0.138     0.0747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/30      9.92G      1.682      1.522     0.9941        600        640: 100%|██████████| 405/405 [00:33<00:00, 12.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:02<00:00,  7.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.246      0.205      0.168     0.0926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/30      9.35G      1.642      1.421     0.9825        702        640: 100%|██████████| 405/405 [00:32<00:00, 12.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:02<00:00,  7.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.273      0.222      0.192      0.107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/30      6.48G      1.608      1.345     0.9743        385        640: 100%|██████████| 405/405 [00:32<00:00, 12.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:02<00:00,  7.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.297      0.241      0.219       0.12\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/30       8.7G      1.592      1.309      0.969        469        640: 100%|██████████| 405/405 [00:31<00:00, 12.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:02<00:00,  7.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.321      0.252      0.226      0.126\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/30      8.66G      1.573      1.268     0.9606        584        640: 100%|██████████| 405/405 [00:32<00:00, 12.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:02<00:00,  8.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.319      0.253      0.227      0.127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/30      7.34G      1.551       1.24     0.9599        862        640: 100%|██████████| 405/405 [00:31<00:00, 12.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:02<00:00,  8.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.306      0.266       0.23      0.126\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/30      9.73G       1.54      1.218     0.9527        601        640: 100%|██████████| 405/405 [00:32<00:00, 12.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:02<00:00,  8.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.326      0.264      0.244      0.137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/30      8.58G      1.531      1.205      0.953        474        640: 100%|██████████| 405/405 [00:32<00:00, 12.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:02<00:00,  8.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.356      0.273      0.257      0.146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/30      9.55G      1.518       1.18     0.9508        665        640: 100%|██████████| 405/405 [00:32<00:00, 12.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:02<00:00,  7.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.342       0.28      0.254      0.143\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/30      9.25G      1.503      1.168     0.9464        361        640: 100%|██████████| 405/405 [00:32<00:00, 12.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:02<00:00,  8.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.346      0.281       0.26      0.147\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/30      10.9G      1.498      1.155     0.9454        378        640: 100%|██████████| 405/405 [00:32<00:00, 12.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:02<00:00,  8.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.374      0.283       0.27      0.152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/30      6.16G      1.496      1.143     0.9436        537        640: 100%|██████████| 405/405 [00:31<00:00, 12.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:02<00:00,  8.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.359      0.282      0.266      0.152\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/30      8.13G      1.472      1.127     0.9382        674        640: 100%|██████████| 405/405 [00:32<00:00, 12.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:02<00:00,  8.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.383      0.287      0.275      0.157\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/30      10.7G      1.477      1.123     0.9391        454        640: 100%|██████████| 405/405 [00:32<00:00, 12.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:02<00:00,  7.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.383      0.293      0.283      0.161\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/30      10.4G       1.47      1.113     0.9369        607        640: 100%|██████████| 405/405 [00:32<00:00, 12.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:02<00:00,  7.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.389      0.286      0.283      0.161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/30      7.51G      1.455      1.096     0.9361        660        640: 100%|██████████| 405/405 [00:32<00:00, 12.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:02<00:00,  8.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.384      0.294      0.283       0.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/30      8.39G       1.46      1.092     0.9332        552        640: 100%|██████████| 405/405 [00:32<00:00, 12.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:02<00:00,  8.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759       0.39      0.294      0.287      0.163\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/30      6.68G       1.45      1.086     0.9317        309        640: 100%|██████████| 405/405 [00:32<00:00, 12.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:02<00:00,  8.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.405      0.297       0.29      0.165\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/30      7.22G      1.443      1.073     0.9326        639        640: 100%|██████████| 405/405 [00:32<00:00, 12.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:02<00:00,  8.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.402      0.298       0.29      0.165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/30       8.5G      1.413      1.058     0.9306        370        640: 100%|██████████| 405/405 [00:30<00:00, 13.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:02<00:00,  8.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.394      0.294      0.284      0.164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/30      6.99G      1.395      1.034     0.9274        319        640: 100%|██████████| 405/405 [00:29<00:00, 13.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:02<00:00,  7.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.395      0.287      0.287      0.165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/30      7.52G      1.389      1.023     0.9256        409        640: 100%|██████████| 405/405 [00:30<00:00, 13.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:02<00:00,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.394      0.293      0.289      0.166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/30       8.5G      1.383      1.012     0.9248        275        640: 100%|██████████| 405/405 [00:31<00:00, 12.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:02<00:00,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.389        0.3      0.291      0.166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/30      9.18G      1.377      1.002     0.9232        244        640: 100%|██████████| 405/405 [00:31<00:00, 12.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:02<00:00,  7.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759       0.42      0.299      0.299       0.17\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/30      7.57G      1.371     0.9966     0.9217        323        640: 100%|██████████| 405/405 [00:31<00:00, 12.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:02<00:00,  7.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.402      0.301      0.297      0.169\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/30      8.76G      1.365     0.9851     0.9194        431        640: 100%|██████████| 405/405 [00:31<00:00, 12.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:02<00:00,  7.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.396      0.309        0.3      0.172\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/30      6.73G      1.361     0.9835     0.9171        273        640: 100%|██████████| 405/405 [00:31<00:00, 12.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:02<00:00,  7.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.409      0.305      0.301      0.173\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/30       7.7G      1.355     0.9765     0.9166        287        640: 100%|██████████| 405/405 [00:31<00:00, 12.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:02<00:00,  7.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.406      0.304      0.299      0.172\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/30      8.49G      1.347     0.9666     0.9152        216        640: 100%|██████████| 405/405 [00:31<00:00, 12.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:02<00:00,  7.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.408      0.304      0.301      0.174\n",
      "\n",
      "30 epochs completed in 0.296 hours.\n",
      "Optimizer stripped from runs\\detect\\train6\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from runs\\detect\\train6\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating runs\\detect\\train6\\weights\\best.pt...\n",
      "Ultralytics 8.3.40  Python-3.12.4 torch-2.5.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4080, 16376MiB)\n",
      "Model summary (fused): 168 layers, 3,007,598 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.409      0.303      0.301      0.174\n",
      "            pedestrian        520       8844      0.408      0.314      0.309       0.13\n",
      "                people        482       5125      0.478      0.206      0.248     0.0873\n",
      "               bicycle        364       1287      0.207       0.08     0.0626      0.024\n",
      "                   car        515      14064      0.579      0.733      0.727      0.489\n",
      "                   van        421       1975       0.44      0.335      0.339      0.233\n",
      "                 truck        266        750      0.462      0.284      0.295      0.199\n",
      "              tricycle        337       1045        0.4      0.211       0.21      0.109\n",
      "       awning-tricycle        220        532      0.211      0.141      0.109     0.0718\n",
      "                   bus        131        251      0.503      0.375      0.402      0.278\n",
      "                 motor        485       4886      0.401       0.35      0.312      0.123\n",
      "Speed: 0.2ms preprocess, 0.8ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train6\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# nano 모델로 시작\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# 학습 시작\n",
    "results = model.train(\n",
    "   data=os.path.join(BASE_DIR, 'visdrone.yaml'),\n",
    "   epochs=30,\n",
    "   patience=5,\n",
    "   imgsz=640,  \n",
    "   batch=16,  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.47 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.40  Python-3.12.4 torch-2.5.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4080, 16376MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=C:/Users/sonym/20242R0136COSE47402/pretrained\\visdrone.yaml, epochs=30, time=None, patience=5, batch=16, imgsz=1024, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=visdrone_detection_fem_cbam3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=0, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=True, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\visdrone_detection_fem_cbam3\n",
      "Overriding model.yaml nc=80 with nc=10\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    753262  ultralytics.nn.modules.head.Detect           [10, [64, 128, 256]]          \n",
      "Model summary: 225 layers, 3,012,798 parameters, 3,012,782 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 295/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\visdrone_detection_fem_cbam3', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\sonym\\20242R0136COSE47402\\pretrained\\train\\labels.cache... 6471 images, 0 backgrounds, 0 corrupt: 100%|██████████| 6471/6471 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\sonym\\20242R0136COSE47402\\pretrained\\train\\images\\0000137_02220_d_0000163.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\sonym\\20242R0136COSE47402\\pretrained\\train\\images\\0000140_00118_d_0000002.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\sonym\\20242R0136COSE47402\\pretrained\\train\\images\\9999945_00000_d_0000114.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\sonym\\20242R0136COSE47402\\pretrained\\train\\images\\9999987_00000_d_0000049.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\sonym\\20242R0136COSE47402\\pretrained\\val\\labels.cache... 548 images, 0 backgrounds, 0 corrupt: 100%|██████████| 548/548 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\visdrone_detection_fem_cbam3\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 1024 train, 1024 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\visdrone_detection_fem_cbam3\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/30     0.543G      1.643      2.256      1.077        476       1024: 100%|██████████| 405/405 [04:05<00:00,  1.65it/s] \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:05<00:00,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.262       0.24      0.204      0.116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/30        12G      1.519      1.465      1.031        611       1024: 100%|██████████| 405/405 [03:14<00:00,  2.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:03<00:00,  4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.341      0.303      0.263      0.151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/30      15.4G      1.491      1.353      1.019        710       1024: 100%|██████████| 405/405 [01:53<00:00,  3.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:03<00:00,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.372      0.324       0.29      0.169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/30      20.5G      1.464      1.275       1.01        393       1024: 100%|██████████| 405/405 [02:17<00:00,  2.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:03<00:00,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.387      0.333      0.312      0.181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/30      26.8G      1.454      1.236      1.005        475       1024: 100%|██████████| 405/405 [02:39<00:00,  2.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:03<00:00,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.412      0.336      0.322      0.191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/30      14.9G       1.44       1.19     0.9973        600       1024: 100%|██████████| 405/405 [01:39<00:00,  4.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:03<00:00,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.435      0.342      0.338        0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/30      21.6G      1.423      1.164     0.9945        912       1024: 100%|██████████| 405/405 [02:23<00:00,  2.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:03<00:00,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.442      0.342      0.334      0.198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/30      21.3G      1.412      1.146     0.9879        644       1024: 100%|██████████| 405/405 [06:31<00:00,  1.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:25<00:00,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.441      0.353       0.35      0.206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/30      18.9G      1.408      1.128     0.9879        501       1024: 100%|██████████| 405/405 [02:00<00:00,  3.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:05<00:00,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.445       0.36      0.358      0.213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/30        26G      1.399      1.107      0.987        718       1024: 100%|██████████| 405/405 [02:58<00:00,  2.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:06<00:00,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.427      0.377      0.365      0.218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/30      23.4G      1.379       1.09     0.9796        377       1024: 100%|██████████| 405/405 [03:24<00:00,  1.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:04<00:00,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.462      0.364       0.37      0.224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/30      24.9G      1.381      1.081     0.9794        386       1024: 100%|██████████| 405/405 [02:43<00:00,  2.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:03<00:00,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.471      0.379       0.38      0.226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/30      19.5G      1.377      1.068     0.9769        560       1024: 100%|██████████| 405/405 [02:32<00:00,  2.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:04<00:00,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.456      0.378      0.377      0.228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/30      22.6G      1.357       1.05     0.9719        693       1024: 100%|██████████| 405/405 [02:03<00:00,  3.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:03<00:00,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759       0.49      0.384       0.39      0.236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/30      17.1G      1.361      1.045     0.9728        473       1024: 100%|██████████| 405/405 [09:34<00:00,  1.42s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:22<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759       0.47      0.389      0.389      0.235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/30      20.3G      1.359      1.039     0.9713        658       1024: 100%|██████████| 405/405 [05:00<00:00,  1.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:10<00:00,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.484      0.386      0.395       0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/30      26.5G      1.345      1.025     0.9705        709       1024: 100%|██████████| 405/405 [01:40<00:00,  4.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:03<00:00,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.487      0.382      0.392      0.237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/30      26.5G      1.349      1.019     0.9671        579       1024: 100%|██████████| 405/405 [02:53<00:00,  2.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:03<00:00,  5.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759       0.48      0.393      0.402      0.243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/30      19.1G       1.34      1.013     0.9661        314       1024: 100%|██████████| 405/405 [01:21<00:00,  5.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:03<00:00,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.491      0.396      0.405      0.242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/30      15.5G      1.336      1.003     0.9669        656       1024: 100%|██████████| 405/405 [01:00<00:00,  6.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:03<00:00,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.507      0.389      0.402      0.242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/30      21.6G      1.324     0.9968     0.9701        382       1024: 100%|██████████| 405/405 [01:25<00:00,  4.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:03<00:00,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.506      0.389      0.404      0.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/30      18.5G       1.31     0.9732     0.9666        348       1024: 100%|██████████| 405/405 [01:15<00:00,  5.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:05<00:00,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.476      0.396      0.401      0.242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/30      18.9G      1.305     0.9643     0.9639        409       1024: 100%|██████████| 405/405 [01:08<00:00,  5.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:03<00:00,  5.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.511      0.393      0.407      0.248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/30      21.8G      1.299     0.9574     0.9621        277       1024: 100%|██████████| 405/405 [01:09<00:00,  5.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:03<00:00,  5.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.508      0.395      0.408      0.248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/30      22.5G      1.296     0.9483     0.9624        244       1024: 100%|██████████| 405/405 [02:27<00:00,  2.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:09<00:00,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.511      0.399      0.412      0.251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/30      23.4G       1.29     0.9404     0.9602        328       1024: 100%|██████████| 405/405 [01:36<00:00,  4.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:04<00:00,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.507      0.403      0.416      0.254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/30      20.6G      1.283     0.9305      0.957        449       1024: 100%|██████████| 405/405 [01:08<00:00,  5.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:03<00:00,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.513      0.408      0.418      0.253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/30      19.8G      1.281     0.9275     0.9563        274       1024: 100%|██████████| 405/405 [01:18<00:00,  5.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.521      0.399      0.417      0.254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/30      20.8G      1.275       0.92     0.9546        296       1024: 100%|██████████| 405/405 [01:27<00:00,  4.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:03<00:00,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.511      0.404      0.418      0.254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/30      23.5G      1.271      0.915     0.9539        224       1024: 100%|██████████| 405/405 [01:19<00:00,  5.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:02<00:00,  6.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.526      0.402       0.42      0.256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "30 epochs completed in 1.343 hours.\n",
      "Optimizer stripped from runs\\detect\\visdrone_detection_fem_cbam3\\weights\\last.pt, 6.3MB\n",
      "Optimizer stripped from runs\\detect\\visdrone_detection_fem_cbam3\\weights\\best.pt, 6.3MB\n",
      "\n",
      "Validating runs\\detect\\visdrone_detection_fem_cbam3\\weights\\best.pt...\n",
      "Ultralytics 8.3.40  Python-3.12.4 torch-2.5.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4080, 16376MiB)\n",
      "Model summary (fused): 168 layers, 3,007,598 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:11<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.497      0.393      0.406       0.25\n",
      "            pedestrian        520       8844      0.532      0.426      0.453      0.217\n",
      "                people        482       5125      0.553      0.299      0.357      0.144\n",
      "               bicycle        364       1287      0.364       0.17      0.167     0.0769\n",
      "                   car        515      14064      0.664       0.79      0.803      0.574\n",
      "                   van        421       1975      0.525      0.448       0.45      0.327\n",
      "                 truck        266        750      0.469      0.382      0.374      0.264\n",
      "              tricycle        337       1045      0.476      0.269      0.289      0.169\n",
      "       awning-tricycle        220        532      0.277      0.203      0.165      0.112\n",
      "                   bus        131        251      0.583      0.514      0.551      0.414\n",
      "                 motor        485       4886      0.529      0.431      0.449      0.205\n",
      "Speed: 0.1ms preprocess, 4.6ms inference, 0.0ms loss, 6.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\visdrone_detection_fem_cbam3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from ultralytics import YOLO\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# CBAM 모듈 예시 (채널+공간 어텐션)\n",
    "class CBAMBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super().__init__()\n",
    "        # Channel Attention\n",
    "        self.channel_att = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(channels, channels // reduction, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(channels // reduction, channels, 1)\n",
    "        )\n",
    "        # Spatial Attention\n",
    "        self.spatial_att = nn.Sequential(\n",
    "            nn.Conv2d(2, 1, 7, padding=3),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Channel Attention\n",
    "        avg_out = self.channel_att(x)\n",
    "        max_out = self.channel_att(torch.max(x, dim=1, keepdim=True)[0])\n",
    "        channel_att = torch.sigmoid(avg_out + max_out)\n",
    "        x = x * channel_att\n",
    "\n",
    "        # Spatial Attention\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        spatial_in = torch.cat([avg_out, max_out], dim=1)\n",
    "        spatial_att = self.spatial_att(spatial_in)\n",
    "        x = x * spatial_att\n",
    "        return x\n",
    "\n",
    "\n",
    "# 개선된 FEM 모듈 예시\n",
    "class FeatureEnhancementModule(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        # 채널 축소 및 그룹 컨볼루션 활용\n",
    "        reduced_channels = in_channels // 4\n",
    "        self.reduce = nn.Conv2d(in_channels, reduced_channels, 1, bias=False)\n",
    "\n",
    "        self.conv3x3 = nn.Conv2d(reduced_channels, reduced_channels, 3, padding=1, groups=reduced_channels, bias=False)\n",
    "        self.conv5x5 = nn.Conv2d(reduced_channels, reduced_channels, 5, padding=2, groups=reduced_channels, bias=False)\n",
    "\n",
    "        self.bn = nn.BatchNorm2d(reduced_channels * 2)  # concat 후 batchnorm\n",
    "        self.cbam = CBAMBlock(reduced_channels * 2, reduction=16)\n",
    "\n",
    "        self.expand = nn.Conv2d(reduced_channels * 2, in_channels, 1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.reduce(x)\n",
    "        feat3x3 = self.conv3x3(x)\n",
    "        feat5x5 = self.conv5x5(x)\n",
    "        feat_cat = torch.cat([feat3x3, feat5x5], dim=1)\n",
    "        feat_cat = self.bn(feat_cat)\n",
    "        feat_att = self.cbam(feat_cat)\n",
    "        return self.expand(feat_att)\n",
    "\n",
    "\n",
    "# CUDA 최적화 설정\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# 모델 로드 (yolov8m.pt 대신 다른 모델도 시도 가능)\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# in_channels 확인 후 FEM 모듈 삽입\n",
    "in_channels = 768  # yolov8m neck 마지막 출력 채널(모델 구조 print 참고)\n",
    "fem = FeatureEnhancementModule(in_channels)\n",
    "\n",
    "neck_last_layer = model.model.model[-2]\n",
    "detect_layer = model.model.model[-1]\n",
    "\n",
    "model.model.model = nn.Sequential(\n",
    "    *list(model.model.model[:-2]),\n",
    "    nn.Sequential(\n",
    "        neck_last_layer,\n",
    "        fem\n",
    "    ),\n",
    "    detect_layer\n",
    ")\n",
    "\n",
    "# 모든 파라미터 학습 가능하도록 설정\n",
    "for param in model.model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# 경로 설정 (사용자 환경에 맞게 수정)\n",
    "BASE_DIR = 'C:/Users/sonym/20242R0136COSE47402/pretrained'\n",
    "VISDRONE_YAML = os.path.join(BASE_DIR, 'visdrone.yaml')\n",
    "\n",
    "# Augmentation 활성화 (data.yaml에서 mosaic, mixup 등 설정하거나 train 파라미터로 지정)\n",
    "# 예: model.train(augment=True) 또는 data.yaml 내 augmentation 항목 조정\n",
    "\n",
    "# 학습 시작\n",
    "# epochs 증가(예: 50으로), scheduler 사용 등의 미세 조정 가능\n",
    "results = model.train(\n",
    "    data=VISDRONE_YAML,\n",
    "    epochs=30,      \n",
    "    patience=5,\n",
    "    imgsz=1024,\n",
    "    batch=16,\n",
    "    name='visdrone_detection_fem_cbam',\n",
    "    freeze=0,\n",
    "    half=True,       \n",
    "    verbose=True,       \n",
    "    augment=True        # 기본 augmentation 활성화\n",
    ")\n",
    "\n",
    "# 이후 필요하다면 일정 에폭 후 Backbone Freeze/Unfreeze 전략, LR scheduler 조정, 데이터 증강 다양화 등을 추가 실험\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
